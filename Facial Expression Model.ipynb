{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from os.path import join, exists\n",
    "\n",
    "from FaceDetector_class import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    'Angry': 0,\n",
    "    'Disgust': 1,\n",
    "    'Fear': 2,\n",
    "    'Happy': 3,\n",
    "    'Sad': 4,\n",
    "    'Surprise': 5,\n",
    "    'Neutral': 6\n",
    "}\n",
    "\n",
    "CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
    "CIFAR_STD = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "PRINT_FREQ = 100\n",
    "TRAIN_NUMS = 30016\n",
    "\n",
    "CUDA = True\n",
    "\n",
    "PATH_TO_SAVE_DATA = \"./\"\n",
    "\n",
    "TRAIN_PATH = \"./dataset/fer2013/train/\"\n",
    "VAL_PATH = \"./dataset/fer2013/val/\"\n",
    "TEST_PATH = \"./dataset/fer2013/test/\"\n",
    "\n",
    "DATASET_PATH = \"./dataset/fer2013/\"\n",
    "MODEL_PATH = \"./model/model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(join(DATASET_PATH, x), data_transforms[x]) for x in ['train', 'test']}\n",
    "n_train = len(image_datasets['train'])\n",
    "dataloader = {}\n",
    "dataloader['train'] = DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS)), num_workers=4)\n",
    "dataloader['val'] = DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS, n_train)), num_workers=4)\n",
    "dataloader['test'] = DataLoader(image_datasets['test'], batch_size=BATCH_SIZE, num_workers=4)\n",
    "# dataloader = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'test']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA\n",
    "# testing CUDA is available or not\n",
    "if CUDA:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training class\n",
    "class Trainer:\n",
    "    def __init__(self, criterion, optimizer, device):\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def train_loop(self, model, train_loader, val_loader):\n",
    "        for epoch in range(EPOCHS):\n",
    "            print(\"---------------- Epoch {} ----------------\".format(epoch+1))\n",
    "            self._training_step(model, train_loader, epoch)\n",
    "            \n",
    "            self._validate(model, val_loader, epoch)\n",
    "    \n",
    "    def test(self, model, test_loader):\n",
    "            print(\"---------------- Testing ----------------\")\n",
    "            self._validate(model, test_loader, 0, state=\"Testing\")\n",
    "            \n",
    "    def _training_step(self, model, loader, epoch):\n",
    "        model.train()\n",
    "        \n",
    "        for step, (X, y) in enumerate(loader):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            N = X.shape[0]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outs = model(X)\n",
    "            loss = self.criterion(outs, y)\n",
    "            \n",
    "            if step >= 0 and (step % PRINT_FREQ == 0):\n",
    "                self._state_logging(outs, y, loss, step, epoch, \"Training\")\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "            \n",
    "    def _validate(self, model, loader, epoch, state=\"Validate\"):\n",
    "        model.eval()\n",
    "        outs_list = []\n",
    "        loss_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (X, y) in enumerate(loader):\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                N = X.shape[0]\n",
    "                \n",
    "                outs = model(X)\n",
    "                loss = self.criterion(outs, y)\n",
    "                \n",
    "                y_list.append(y)\n",
    "                outs_list.append(outs)\n",
    "                loss_list.append(loss)\n",
    "            \n",
    "            y = torch.cat(y_list)\n",
    "            outs = torch.cat(outs_list)\n",
    "            loss = torch.mean(torch.stack(loss_list), dim=0)\n",
    "            self._state_logging(outs, y, loss, step, epoch, state)\n",
    "                \n",
    "                \n",
    "    def _state_logging(self, outs, y, loss, step, epoch, state):\n",
    "        acc = self._accuracy(outs, y)\n",
    "        print(\"[{:3d}/{}] {} Step {:03d} Loss {:.3f} Acc {:.3f}\".format(epoch+1, EPOCHS, state, step, loss, acc))\n",
    "            \n",
    "    def _accuracy(self, output, target):\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        pred = output.argmax(1)\n",
    "        correct = pred.eq(target)\n",
    "        acc = correct.float().sum(0) / batch_size\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_classes=7, model_type='VGG11'):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[model_type])\n",
    "        self.feature_map = []\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 7),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "    \n",
    "        out = self.features(x)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]             640\n",
      "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
      "              ReLU-3           [-1, 64, 48, 48]               0\n",
      "         MaxPool2d-4           [-1, 64, 24, 24]               0\n",
      "            Conv2d-5          [-1, 128, 24, 24]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 24, 24]             256\n",
      "              ReLU-7          [-1, 128, 24, 24]               0\n",
      "         MaxPool2d-8          [-1, 128, 12, 12]               0\n",
      "            Conv2d-9          [-1, 256, 12, 12]         295,168\n",
      "      BatchNorm2d-10          [-1, 256, 12, 12]             512\n",
      "             ReLU-11          [-1, 256, 12, 12]               0\n",
      "           Conv2d-12          [-1, 256, 12, 12]         590,080\n",
      "      BatchNorm2d-13          [-1, 256, 12, 12]             512\n",
      "             ReLU-14          [-1, 256, 12, 12]               0\n",
      "        MaxPool2d-15            [-1, 256, 6, 6]               0\n",
      "           Conv2d-16            [-1, 512, 6, 6]       1,180,160\n",
      "      BatchNorm2d-17            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-18            [-1, 512, 6, 6]               0\n",
      "           Conv2d-19            [-1, 512, 6, 6]       2,359,808\n",
      "      BatchNorm2d-20            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-21            [-1, 512, 6, 6]               0\n",
      "        MaxPool2d-22            [-1, 512, 3, 3]               0\n",
      "           Conv2d-23            [-1, 512, 3, 3]       2,359,808\n",
      "      BatchNorm2d-24            [-1, 512, 3, 3]           1,024\n",
      "             ReLU-25            [-1, 512, 3, 3]               0\n",
      "           Conv2d-26            [-1, 512, 3, 3]       2,359,808\n",
      "      BatchNorm2d-27            [-1, 512, 3, 3]           1,024\n",
      "             ReLU-28            [-1, 512, 3, 3]               0\n",
      "        MaxPool2d-29            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-30            [-1, 512, 1, 1]               0\n",
      "           Linear-31                    [-1, 7]           3,591\n",
      "================================================================\n",
      "Total params: 9,228,423\n",
      "Trainable params: 9,228,423\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 8.34\n",
      "Params size (MB): 35.20\n",
      "Estimated Total Size (MB): 43.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = VGG(model_type='VGG11')\n",
    "model.cuda()\n",
    "summary(model, (1, 48, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=1e-2, momentum=0.9, weight_decay=1e-3) # weight_decay can be smaller\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 1 ----------------\n",
      "[  1/20] Training Step 000 Loss 2.292 Acc 0.094\n",
      "[  1/20] Training Step 100 Loss 1.888 Acc 0.188\n",
      "[  1/20] Training Step 200 Loss 1.734 Acc 0.344\n",
      "[  1/20] Training Step 300 Loss 1.901 Acc 0.125\n",
      "[  1/20] Training Step 400 Loss 1.862 Acc 0.250\n",
      "[  1/20] Training Step 500 Loss 1.786 Acc 0.250\n",
      "[  1/20] Training Step 600 Loss 1.726 Acc 0.312\n",
      "[  1/20] Training Step 700 Loss 1.645 Acc 0.281\n",
      "[  1/20] Training Step 800 Loss 1.480 Acc 0.438\n",
      "[  1/20] Training Step 900 Loss 1.291 Acc 0.562\n",
      "[  1/20] Validate Step 071 Loss 2.214 Acc 0.090\n",
      "---------------- Epoch 2 ----------------\n",
      "[  2/20] Training Step 000 Loss 1.614 Acc 0.344\n",
      "[  2/20] Training Step 100 Loss 1.394 Acc 0.406\n",
      "[  2/20] Training Step 200 Loss 1.516 Acc 0.406\n",
      "[  2/20] Training Step 300 Loss 1.392 Acc 0.438\n",
      "[  2/20] Training Step 400 Loss 1.427 Acc 0.438\n",
      "[  2/20] Training Step 500 Loss 1.531 Acc 0.375\n",
      "[  2/20] Training Step 600 Loss 1.163 Acc 0.500\n",
      "[  2/20] Training Step 700 Loss 1.343 Acc 0.438\n",
      "[  2/20] Training Step 800 Loss 1.107 Acc 0.562\n",
      "[  2/20] Training Step 900 Loss 1.261 Acc 0.562\n",
      "[  2/20] Validate Step 071 Loss 1.935 Acc 0.247\n",
      "---------------- Epoch 3 ----------------\n",
      "[  3/20] Training Step 000 Loss 1.147 Acc 0.438\n",
      "[  3/20] Training Step 100 Loss 1.349 Acc 0.469\n",
      "[  3/20] Training Step 200 Loss 1.630 Acc 0.312\n",
      "[  3/20] Training Step 300 Loss 1.180 Acc 0.594\n",
      "[  3/20] Training Step 400 Loss 1.457 Acc 0.531\n",
      "[  3/20] Training Step 500 Loss 1.326 Acc 0.625\n",
      "[  3/20] Training Step 600 Loss 0.934 Acc 0.688\n",
      "[  3/20] Training Step 700 Loss 1.406 Acc 0.375\n",
      "[  3/20] Training Step 800 Loss 1.165 Acc 0.594\n",
      "[  3/20] Training Step 900 Loss 1.286 Acc 0.562\n",
      "[  3/20] Validate Step 071 Loss 1.795 Acc 0.185\n",
      "---------------- Epoch 4 ----------------\n",
      "[  4/20] Training Step 000 Loss 1.130 Acc 0.562\n",
      "[  4/20] Training Step 100 Loss 1.003 Acc 0.594\n",
      "[  4/20] Training Step 200 Loss 0.999 Acc 0.625\n",
      "[  4/20] Training Step 300 Loss 1.139 Acc 0.562\n",
      "[  4/20] Training Step 400 Loss 1.025 Acc 0.688\n",
      "[  4/20] Training Step 500 Loss 1.360 Acc 0.500\n",
      "[  4/20] Training Step 600 Loss 0.836 Acc 0.750\n",
      "[  4/20] Training Step 700 Loss 1.111 Acc 0.562\n",
      "[  4/20] Training Step 800 Loss 0.734 Acc 0.781\n",
      "[  4/20] Training Step 900 Loss 1.181 Acc 0.469\n",
      "[  4/20] Validate Step 071 Loss 1.921 Acc 0.248\n",
      "---------------- Epoch 5 ----------------\n",
      "[  5/20] Training Step 000 Loss 1.128 Acc 0.594\n",
      "[  5/20] Training Step 100 Loss 0.764 Acc 0.750\n",
      "[  5/20] Training Step 200 Loss 1.268 Acc 0.500\n",
      "[  5/20] Training Step 300 Loss 0.914 Acc 0.750\n",
      "[  5/20] Training Step 400 Loss 0.865 Acc 0.719\n",
      "[  5/20] Training Step 500 Loss 0.937 Acc 0.750\n",
      "[  5/20] Training Step 600 Loss 1.006 Acc 0.656\n",
      "[  5/20] Training Step 700 Loss 1.171 Acc 0.500\n",
      "[  5/20] Training Step 800 Loss 1.105 Acc 0.531\n",
      "[  5/20] Training Step 900 Loss 0.969 Acc 0.688\n",
      "[  5/20] Validate Step 071 Loss 1.655 Acc 0.266\n",
      "---------------- Epoch 6 ----------------\n",
      "[  6/20] Training Step 000 Loss 0.742 Acc 0.719\n",
      "[  6/20] Training Step 100 Loss 1.022 Acc 0.562\n",
      "[  6/20] Training Step 200 Loss 0.860 Acc 0.688\n",
      "[  6/20] Training Step 300 Loss 1.236 Acc 0.656\n",
      "[  6/20] Training Step 400 Loss 1.161 Acc 0.531\n",
      "[  6/20] Training Step 500 Loss 0.980 Acc 0.594\n",
      "[  6/20] Training Step 600 Loss 1.072 Acc 0.625\n",
      "[  6/20] Training Step 700 Loss 1.239 Acc 0.500\n",
      "[  6/20] Training Step 800 Loss 1.066 Acc 0.594\n",
      "[  6/20] Training Step 900 Loss 1.039 Acc 0.594\n",
      "[  6/20] Validate Step 071 Loss 2.057 Acc 0.215\n",
      "---------------- Epoch 7 ----------------\n",
      "[  7/20] Training Step 000 Loss 1.247 Acc 0.469\n",
      "[  7/20] Training Step 100 Loss 1.026 Acc 0.625\n",
      "[  7/20] Training Step 200 Loss 0.720 Acc 0.719\n",
      "[  7/20] Training Step 300 Loss 0.871 Acc 0.750\n",
      "[  7/20] Training Step 400 Loss 1.222 Acc 0.438\n",
      "[  7/20] Training Step 500 Loss 1.155 Acc 0.500\n",
      "[  7/20] Training Step 600 Loss 0.825 Acc 0.781\n",
      "[  7/20] Training Step 700 Loss 0.935 Acc 0.656\n",
      "[  7/20] Training Step 800 Loss 1.052 Acc 0.531\n",
      "[  7/20] Training Step 900 Loss 1.147 Acc 0.531\n",
      "[  7/20] Validate Step 071 Loss 1.251 Acc 0.541\n",
      "---------------- Epoch 8 ----------------\n",
      "[  8/20] Training Step 000 Loss 0.707 Acc 0.750\n",
      "[  8/20] Training Step 100 Loss 0.907 Acc 0.656\n",
      "[  8/20] Training Step 200 Loss 0.974 Acc 0.594\n",
      "[  8/20] Training Step 300 Loss 1.072 Acc 0.531\n",
      "[  8/20] Training Step 400 Loss 0.831 Acc 0.656\n",
      "[  8/20] Training Step 500 Loss 1.146 Acc 0.562\n",
      "[  8/20] Training Step 600 Loss 0.983 Acc 0.594\n",
      "[  8/20] Training Step 700 Loss 0.648 Acc 0.719\n",
      "[  8/20] Training Step 800 Loss 1.067 Acc 0.656\n",
      "[  8/20] Training Step 900 Loss 0.901 Acc 0.625\n",
      "[  8/20] Validate Step 071 Loss 1.686 Acc 0.384\n",
      "---------------- Epoch 9 ----------------\n",
      "[  9/20] Training Step 000 Loss 0.936 Acc 0.688\n",
      "[  9/20] Training Step 100 Loss 0.780 Acc 0.719\n",
      "[  9/20] Training Step 200 Loss 0.928 Acc 0.625\n",
      "[  9/20] Training Step 300 Loss 1.036 Acc 0.656\n",
      "[  9/20] Training Step 400 Loss 1.031 Acc 0.594\n",
      "[  9/20] Training Step 500 Loss 0.663 Acc 0.719\n",
      "[  9/20] Training Step 600 Loss 0.815 Acc 0.656\n",
      "[  9/20] Training Step 700 Loss 1.024 Acc 0.594\n",
      "[  9/20] Training Step 800 Loss 1.069 Acc 0.562\n",
      "[  9/20] Training Step 900 Loss 0.775 Acc 0.656\n",
      "[  9/20] Validate Step 071 Loss 1.133 Acc 0.571\n",
      "---------------- Epoch 10 ----------------\n",
      "[ 10/20] Training Step 000 Loss 0.693 Acc 0.750\n",
      "[ 10/20] Training Step 100 Loss 0.565 Acc 0.750\n",
      "[ 10/20] Training Step 200 Loss 0.543 Acc 0.781\n",
      "[ 10/20] Training Step 300 Loss 0.695 Acc 0.750\n",
      "[ 10/20] Training Step 400 Loss 0.880 Acc 0.594\n",
      "[ 10/20] Training Step 500 Loss 0.893 Acc 0.625\n",
      "[ 10/20] Training Step 600 Loss 0.783 Acc 0.750\n",
      "[ 10/20] Training Step 700 Loss 0.767 Acc 0.688\n",
      "[ 10/20] Training Step 800 Loss 0.912 Acc 0.656\n",
      "[ 10/20] Training Step 900 Loss 0.463 Acc 0.844\n",
      "[ 10/20] Validate Step 071 Loss 1.535 Acc 0.423\n",
      "---------------- Epoch 11 ----------------\n",
      "[ 11/20] Training Step 000 Loss 0.756 Acc 0.719\n",
      "[ 11/20] Training Step 100 Loss 0.734 Acc 0.656\n",
      "[ 11/20] Training Step 200 Loss 0.640 Acc 0.781\n",
      "[ 11/20] Training Step 300 Loss 0.779 Acc 0.719\n",
      "[ 11/20] Training Step 400 Loss 0.740 Acc 0.812\n",
      "[ 11/20] Training Step 500 Loss 0.686 Acc 0.781\n",
      "[ 11/20] Training Step 600 Loss 0.813 Acc 0.688\n",
      "[ 11/20] Training Step 700 Loss 0.723 Acc 0.688\n",
      "[ 11/20] Training Step 800 Loss 0.876 Acc 0.688\n",
      "[ 11/20] Training Step 900 Loss 0.615 Acc 0.781\n",
      "[ 11/20] Validate Step 071 Loss 1.732 Acc 0.388\n",
      "---------------- Epoch 12 ----------------\n",
      "[ 12/20] Training Step 000 Loss 0.573 Acc 0.812\n",
      "[ 12/20] Training Step 100 Loss 0.951 Acc 0.625\n",
      "[ 12/20] Training Step 200 Loss 0.449 Acc 0.844\n",
      "[ 12/20] Training Step 300 Loss 0.586 Acc 0.812\n",
      "[ 12/20] Training Step 400 Loss 0.627 Acc 0.750\n",
      "[ 12/20] Training Step 500 Loss 0.532 Acc 0.812\n",
      "[ 12/20] Training Step 600 Loss 0.606 Acc 0.750\n",
      "[ 12/20] Training Step 700 Loss 0.728 Acc 0.781\n",
      "[ 12/20] Training Step 800 Loss 0.394 Acc 0.844\n",
      "[ 12/20] Training Step 900 Loss 0.625 Acc 0.844\n",
      "[ 12/20] Validate Step 071 Loss 1.307 Acc 0.567\n",
      "---------------- Epoch 13 ----------------\n",
      "[ 13/20] Training Step 000 Loss 0.449 Acc 0.781\n",
      "[ 13/20] Training Step 100 Loss 0.463 Acc 0.844\n",
      "[ 13/20] Training Step 200 Loss 0.646 Acc 0.781\n",
      "[ 13/20] Training Step 300 Loss 0.489 Acc 0.875\n",
      "[ 13/20] Training Step 400 Loss 0.401 Acc 0.844\n",
      "[ 13/20] Training Step 500 Loss 0.442 Acc 0.812\n",
      "[ 13/20] Training Step 600 Loss 0.723 Acc 0.812\n",
      "[ 13/20] Training Step 700 Loss 0.811 Acc 0.719\n",
      "[ 13/20] Training Step 800 Loss 0.525 Acc 0.750\n",
      "[ 13/20] Training Step 900 Loss 0.521 Acc 0.750\n",
      "[ 13/20] Validate Step 071 Loss 1.744 Acc 0.434\n",
      "---------------- Epoch 14 ----------------\n",
      "[ 14/20] Training Step 000 Loss 0.769 Acc 0.750\n",
      "[ 14/20] Training Step 100 Loss 0.477 Acc 0.844\n",
      "[ 14/20] Training Step 200 Loss 0.472 Acc 0.875\n",
      "[ 14/20] Training Step 300 Loss 0.613 Acc 0.750\n",
      "[ 14/20] Training Step 400 Loss 0.355 Acc 0.906\n",
      "[ 14/20] Training Step 500 Loss 0.556 Acc 0.781\n",
      "[ 14/20] Training Step 600 Loss 0.484 Acc 0.906\n",
      "[ 14/20] Training Step 700 Loss 0.460 Acc 0.844\n",
      "[ 14/20] Training Step 800 Loss 0.376 Acc 0.969\n",
      "[ 14/20] Training Step 900 Loss 0.539 Acc 0.750\n",
      "[ 14/20] Validate Step 071 Loss 1.182 Acc 0.604\n",
      "---------------- Epoch 15 ----------------\n",
      "[ 15/20] Training Step 000 Loss 0.277 Acc 0.906\n",
      "[ 15/20] Training Step 100 Loss 0.310 Acc 0.969\n",
      "[ 15/20] Training Step 200 Loss 0.365 Acc 0.875\n",
      "[ 15/20] Training Step 300 Loss 0.281 Acc 0.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15/20] Training Step 400 Loss 0.256 Acc 0.875\n",
      "[ 15/20] Training Step 500 Loss 0.345 Acc 0.875\n",
      "[ 15/20] Training Step 600 Loss 0.395 Acc 0.875\n",
      "[ 15/20] Training Step 700 Loss 0.287 Acc 0.906\n",
      "[ 15/20] Training Step 800 Loss 0.246 Acc 0.938\n",
      "[ 15/20] Training Step 900 Loss 0.417 Acc 0.844\n",
      "[ 15/20] Validate Step 071 Loss 1.468 Acc 0.571\n",
      "---------------- Epoch 16 ----------------\n",
      "[ 16/20] Training Step 000 Loss 0.394 Acc 0.844\n",
      "[ 16/20] Training Step 100 Loss 0.158 Acc 0.938\n",
      "[ 16/20] Training Step 200 Loss 0.395 Acc 0.844\n",
      "[ 16/20] Training Step 300 Loss 0.256 Acc 0.906\n",
      "[ 16/20] Training Step 400 Loss 0.398 Acc 0.844\n",
      "[ 16/20] Training Step 500 Loss 0.146 Acc 0.938\n",
      "[ 16/20] Training Step 600 Loss 0.213 Acc 0.938\n",
      "[ 16/20] Training Step 700 Loss 0.577 Acc 0.750\n",
      "[ 16/20] Training Step 800 Loss 0.151 Acc 0.969\n",
      "[ 16/20] Training Step 900 Loss 0.326 Acc 0.844\n",
      "[ 16/20] Validate Step 071 Loss 1.658 Acc 0.530\n",
      "---------------- Epoch 17 ----------------\n",
      "[ 17/20] Training Step 000 Loss 0.267 Acc 0.938\n",
      "[ 17/20] Training Step 100 Loss 0.172 Acc 0.969\n",
      "[ 17/20] Training Step 200 Loss 0.323 Acc 0.938\n",
      "[ 17/20] Training Step 300 Loss 0.171 Acc 0.906\n",
      "[ 17/20] Training Step 400 Loss 0.139 Acc 0.969\n",
      "[ 17/20] Training Step 500 Loss 0.068 Acc 1.000\n",
      "[ 17/20] Training Step 600 Loss 0.301 Acc 0.906\n",
      "[ 17/20] Training Step 700 Loss 0.236 Acc 0.906\n",
      "[ 17/20] Training Step 800 Loss 0.123 Acc 0.938\n",
      "[ 17/20] Training Step 900 Loss 0.190 Acc 0.906\n",
      "[ 17/20] Validate Step 071 Loss 2.013 Acc 0.478\n",
      "---------------- Epoch 18 ----------------\n",
      "[ 18/20] Training Step 000 Loss 0.065 Acc 0.969\n",
      "[ 18/20] Training Step 100 Loss 0.123 Acc 0.938\n",
      "[ 18/20] Training Step 200 Loss 0.011 Acc 1.000\n",
      "[ 18/20] Training Step 300 Loss 0.073 Acc 0.969\n",
      "[ 18/20] Training Step 400 Loss 0.110 Acc 0.969\n",
      "[ 18/20] Training Step 500 Loss 0.168 Acc 0.906\n",
      "[ 18/20] Training Step 600 Loss 0.094 Acc 0.969\n",
      "[ 18/20] Training Step 700 Loss 0.086 Acc 0.969\n",
      "[ 18/20] Training Step 800 Loss 0.148 Acc 0.906\n",
      "[ 18/20] Training Step 900 Loss 0.034 Acc 1.000\n",
      "[ 18/20] Validate Step 071 Loss 2.621 Acc 0.417\n",
      "---------------- Epoch 19 ----------------\n",
      "[ 19/20] Training Step 000 Loss 0.091 Acc 0.969\n",
      "[ 19/20] Training Step 100 Loss 0.027 Acc 1.000\n",
      "[ 19/20] Training Step 200 Loss 0.070 Acc 0.969\n",
      "[ 19/20] Training Step 300 Loss 0.075 Acc 0.969\n",
      "[ 19/20] Training Step 400 Loss 0.022 Acc 1.000\n",
      "[ 19/20] Training Step 500 Loss 0.041 Acc 1.000\n",
      "[ 19/20] Training Step 600 Loss 0.152 Acc 0.969\n",
      "[ 19/20] Training Step 700 Loss 0.023 Acc 1.000\n",
      "[ 19/20] Training Step 800 Loss 0.053 Acc 0.969\n",
      "[ 19/20] Training Step 900 Loss 0.010 Acc 1.000\n",
      "[ 19/20] Validate Step 071 Loss 2.373 Acc 0.476\n",
      "---------------- Epoch 20 ----------------\n",
      "[ 20/20] Training Step 000 Loss 0.112 Acc 0.969\n",
      "[ 20/20] Training Step 100 Loss 0.012 Acc 1.000\n",
      "[ 20/20] Training Step 200 Loss 0.039 Acc 1.000\n",
      "[ 20/20] Training Step 300 Loss 0.019 Acc 1.000\n",
      "[ 20/20] Training Step 400 Loss 0.025 Acc 1.000\n",
      "[ 20/20] Training Step 500 Loss 0.016 Acc 1.000\n",
      "[ 20/20] Training Step 600 Loss 0.084 Acc 0.969\n",
      "[ 20/20] Training Step 700 Loss 0.011 Acc 1.000\n",
      "[ 20/20] Training Step 800 Loss 0.023 Acc 1.000\n",
      "[ 20/20] Training Step 900 Loss 0.057 Acc 1.000\n",
      "[ 20/20] Validate Step 071 Loss 2.364 Acc 0.481\n",
      "---------------- Testing ----------------\n",
      "[  1/20] Testing Step 112 Loss 1.549 Acc 0.656\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "trainer = Trainer(criterion, optimizer, device)\n",
    "trainer.train_loop(model, dataloader['train'], dataloader['val'])\n",
    "trainer.test(model, dataloader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = VGG(model_type='VGG11')\n",
    "new_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "new_model.eval()\n",
    "new_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from FaceDetector_class import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "face_detector = FaceDetector()\n",
    "img = cv2.imread('test2.jpg')\n",
    "faces = face_detector.FaceDetect(img)\n",
    "print(len(faces))\n",
    "\n",
    "crop_images = []\n",
    "if len(faces) > 0:\n",
    "    for (x,y,width,height) in faces:\n",
    "        #cv2.rectangle(img, (x,y), (x + width,y + height), (255,0,0), 3)\n",
    "        crop_images.append(img[y:y + height, x:x+width])\n",
    "print(len(crop_images))\n",
    "# for crop_image in crop_images:\n",
    "#     cv2.imshow('Face Detection',crop_image)\n",
    "#     cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 48, 48])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# new_img = Image.open('00000.jpg').convert('LA')\n",
    "# new_img = loader(new_img).unsqueeze(1) # why squeeze 1?\n",
    "# print(new_img.shape)\n",
    "\n",
    "# print(type(crop_images[1]))\n",
    "img = crop_images[0]\n",
    "# cv2.imshow('Face Detection',crop_image)\n",
    "# cv2.waitKey(0)\n",
    "img = Image.fromarray(img)\n",
    "img = img.convert('LA')\n",
    "img = img.resize((48, 48))\n",
    "loader = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "img = loader(img).unsqueeze(1)\n",
    "print(img.shape)\n",
    "img = img.to(device)\n",
    "print(type(img))\n",
    "out = new_model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2418, -9.1218, -6.8590, 19.2342, -2.8608, -2.1292, -0.2990],\n",
      "        [-0.5662, -4.4643,  1.7400,  0.1814,  0.4606,  0.1083,  2.4321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
